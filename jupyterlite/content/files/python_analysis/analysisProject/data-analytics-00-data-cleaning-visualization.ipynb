{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea94a3ad",
   "metadata": {},
   "source": [
    "# Data Cleaning and Visualization\n",
    "\n",
    "## Learning Objectives\n",
    "In this lesson, you will learn to:\n",
    "1. Load and inspect messy datasets\n",
    "2. Clean data by handling missing values, duplicates, and outliers\n",
    "3. Filter and subset data based on conditions\n",
    "4. Transform and prepare data for visualization\n",
    "5. Create professional visualizations using matplotlib and pandas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da14c7",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Inspecting Data\n",
    "\n",
    "Let's start by creating a sample dataset that contains common data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c783ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Import Required Libraries\n",
    "# ========================================\n",
    "# pandas (pd): The primary library for working with tabular data (like spreadsheets)\n",
    "import pandas as pd\n",
    "\n",
    "# numpy (np): Library for numerical computations and array operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib.pyplot (plt): The main plotting library for creating visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datetime modules: For working with dates and times\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ========================================\n",
    "# Configure Settings\n",
    "# ========================================\n",
    "# Set random seed to 42 so everyone gets the same \"random\" data\n",
    "# This makes our code reproducible - you'll get the same results every time\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)  # Show all columns (don't truncate)\n",
    "pd.set_option('display.width', None)        # Use full screen width\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(\"âœ“ Settings configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Create Sample Dataset with Intentional Data Quality Issues\n",
    "# ========================================\n",
    "# We're creating a realistic dataset that has common problems you'll encounter in real data\n",
    "\n",
    "# Set the number of records we want to generate\n",
    "n_records = 500\n",
    "\n",
    "# ----------------------------------------\n",
    "# Generate Random Dates\n",
    "# ----------------------------------------\n",
    "# Create a starting date (January 1, 2024)\n",
    "start_date = datetime(2024, 1, 1)\n",
    "\n",
    "# Generate 500 random dates throughout 2024\n",
    "# This simulates transaction dates spread across the year\n",
    "dates = [start_date + timedelta(days=np.random.randint(0, 365)) for _ in range(n_records)]\n",
    "\n",
    "# ----------------------------------------\n",
    "# Build the Dataset Dictionary\n",
    "# ----------------------------------------\n",
    "# Create a dictionary where each key is a column name and value is a list of data\n",
    "data = {\n",
    "    # Transaction date for each sale\n",
    "    'date': dates,\n",
    "    \n",
    "    # Product names - randomly chosen from 6 different products\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard', 'Mouse'], n_records),\n",
    "    \n",
    "    # Region names - NOTE: Intentionally inconsistent capitalization ('north' vs 'North' vs 'SOUTH')\n",
    "    # This is a common data quality issue we'll need to fix!\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West', 'north', 'SOUTH'], n_records),\n",
    "    \n",
    "    # Sales amount in dollars - random values between $100 and $5,000\n",
    "    'sales': np.random.randint(100, 5000, n_records),\n",
    "    \n",
    "    # Quantity of items sold - random values between 1 and 50\n",
    "    'quantity': np.random.randint(1, 50, n_records),\n",
    "    \n",
    "    # Customer age - random values between 18 and 75\n",
    "    'customer_age': np.random.randint(18, 75, n_records),\n",
    "    \n",
    "    # Customer satisfaction score (1-5 scale, where 5 is best)\n",
    "    'satisfaction': np.random.choice([1, 2, 3, 4, 5], n_records)\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame (like a spreadsheet table)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Introduce Missing Values (10% of data)\n",
    "# ----------------------------------------\n",
    "# Randomly select 10% of rows to have missing data\n",
    "missing_indices = np.random.choice(df.index, size=int(n_records * 0.10), replace=False)\n",
    "\n",
    "# Make half of those rows have missing sales values\n",
    "df.loc[missing_indices[:len(missing_indices)//2], 'sales'] = np.nan\n",
    "\n",
    "# Make the other half have missing satisfaction scores\n",
    "df.loc[missing_indices[len(missing_indices)//2:], 'satisfaction'] = np.nan\n",
    "\n",
    "# ----------------------------------------\n",
    "# Introduce Duplicate Rows\n",
    "# ----------------------------------------\n",
    "# Randomly select 20 rows and duplicate them\n",
    "duplicate_rows = df.sample(20)\n",
    "# Add these duplicate rows to the dataframe (this creates duplicates)\n",
    "df = pd.concat([df, duplicate_rows], ignore_index=True)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Introduce Outliers\n",
    "# ----------------------------------------\n",
    "# Select 10 random rows and give them unrealistically high sales values\n",
    "outlier_indices = np.random.choice(df.index, size=10, replace=False)\n",
    "# Set their sales to be between $50,000 and $100,000 (much higher than normal)\n",
    "df.loc[outlier_indices, 'sales'] = np.random.randint(50000, 100000, len(outlier_indices))\n",
    "\n",
    "# ----------------------------------------\n",
    "# Display Results\n",
    "# ----------------------------------------\n",
    "print(f\"âœ“ Dataset created with {len(df)} records\")\n",
    "print(f\"âœ“ Includes: missing values, duplicates, outliers, and inconsistent data\")\n",
    "print(f\"\\nFirst 10 rows of the dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade80815",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Initial Data Inspection\n",
    "\n",
    "Let's examine the dataset to identify data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Display Basic Dataset Information\n",
    "# ========================================\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# .info() shows: column names, data types, non-null counts, and memory usage\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDataset Shape:\")\n",
    "# .shape returns a tuple: (number of rows, number of columns)\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514697d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Check for Missing Values\n",
    "# ========================================\n",
    "print(\"Missing Values Count:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# .isnull() returns True for missing values, .sum() counts them\n",
    "missing = df.isnull().sum()\n",
    "\n",
    "# Calculate what percentage of each column is missing\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Create a summary DataFrame showing both count and percentage\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "\n",
    "# Only show columns that actually have missing values\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa28676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Check for Duplicate Rows\n",
    "# ========================================\n",
    "# .duplicated() returns True for rows that are exact copies of earlier rows\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Show some example duplicate rows\n",
    "print(f\"\\nSample duplicate rows:\")\n",
    "# keep=False marks ALL duplicates (not just the second occurrence)\n",
    "df[df.duplicated(keep=False)].sort_values('date').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9570748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Check for Inconsistent Values\n",
    "# ========================================\n",
    "# Look at the unique values in categorical columns\n",
    "\n",
    "print(\"Unique values in 'region' column:\")\n",
    "# .value_counts() shows each unique value and how many times it appears\n",
    "# Notice: 'North', 'north', and 'SOUTH' - these should be standardized!\n",
    "print(df['region'].value_counts())\n",
    "\n",
    "print(\"\\nUnique values in 'product' column:\")\n",
    "print(df['product'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11618a2",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Data Cleaning\n",
    "\n",
    "Now we'll systematically clean the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7ba52",
   "metadata": {},
   "source": [
    "### Step 2.1: Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01cdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Remove Duplicate Rows\n",
    "# ========================================\n",
    "# Create a copy of the dataframe so we don't modify the original\n",
    "# This is good practice - always preserve your raw data!\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Before removing duplicates: {len(df_clean)} records\")\n",
    "\n",
    "# .drop_duplicates() removes all rows that are exact copies\n",
    "# By default, it keeps the first occurrence and removes later ones\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "print(f\"After removing duplicates: {len(df_clean)} records\")\n",
    "print(f\"Removed {len(df) - len(df_clean)} duplicate records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e611ba3e",
   "metadata": {},
   "source": [
    "### Step 2.2: Standardize Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbceb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Standardize Categorical Data\n",
    "# ========================================\n",
    "# Fix inconsistent capitalization in the 'region' column\n",
    "\n",
    "print(\"Before standardization:\")\n",
    "print(df_clean['region'].value_counts())\n",
    "\n",
    "# .str.title() converts text to Title Case (First Letter Capitalized)\n",
    "# This makes 'north' â†’ 'North', 'SOUTH' â†’ 'South', etc.\n",
    "df_clean['region'] = df_clean['region'].str.title()\n",
    "\n",
    "print(\"\\nAfter standardization:\")\n",
    "print(df_clean['region'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7e8aa",
   "metadata": {},
   "source": [
    "### Step 2.3: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Handle Missing Sales Values\n",
    "# ========================================\n",
    "# Strategy: Fill missing sales with the median sales for that product\n",
    "# Why? Different products have different typical prices, so we use product-specific medians\n",
    "\n",
    "print(\"Handling missing sales values...\")\n",
    "print(f\"Missing sales before: {df_clean['sales'].isnull().sum()}\")\n",
    "\n",
    "# .groupby('product') groups rows by product\n",
    "# .transform() applies the function to each group and returns a Series the same size as the original\n",
    "# lambda x: x.fillna(x.median()) fills missing values with that group's median\n",
    "df_clean['sales'] = df_clean.groupby('product')['sales'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "print(f\"Missing sales after: {df_clean['sales'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c727741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Handle Missing Satisfaction Scores\n",
    "# ========================================\n",
    "# Strategy: Fill with the mode (most common value)\n",
    "# Why? Satisfaction is categorical (1-5), so median might not make sense\n",
    "\n",
    "print(\"Handling missing satisfaction values...\")\n",
    "print(f\"Missing satisfaction before: {df_clean['satisfaction'].isnull().sum()}\")\n",
    "\n",
    "# .mode()[0] gets the most common value (the first mode if there are ties)\n",
    "satisfaction_mode = df_clean['satisfaction'].mode()[0]\n",
    "\n",
    "# .fillna() replaces all NaN (missing) values with the specified value\n",
    "df_clean['satisfaction'] = df_clean['satisfaction'].fillna(satisfaction_mode)\n",
    "\n",
    "print(f\"Missing satisfaction after: {df_clean['satisfaction'].isnull().sum()}\")\n",
    "print(f\"Used mode value: {satisfaction_mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a844d3",
   "metadata": {},
   "source": [
    "### Step 2.4: Identify and Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d55657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Identify Outliers Using IQR Method\n",
    "# ========================================\n",
    "# IQR (Interquartile Range) is a statistical method to detect outliers\n",
    "# It finds values that are unusually far from the middle 50% of the data\n",
    "\n",
    "# Calculate quartiles (25th and 75th percentiles)\n",
    "Q1 = df_clean['sales'].quantile(0.25)  # 25% of data is below this value\n",
    "Q3 = df_clean['sales'].quantile(0.75)  # 75% of data is below this value\n",
    "IQR = Q3 - Q1                           # The range of the middle 50% of data\n",
    "\n",
    "# Calculate outlier boundaries\n",
    "# Values beyond 1.5 Ã— IQR from Q1 or Q3 are considered outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Sales Statistics:\")\n",
    "print(f\"Q1 (25th percentile): ${Q1:,.2f}\")\n",
    "print(f\"Q3 (75th percentile): ${Q3:,.2f}\")\n",
    "print(f\"IQR: ${IQR:,.2f}\")\n",
    "print(f\"\\nOutlier bounds:\")\n",
    "print(f\"Lower bound: ${lower_bound:,.2f}\")\n",
    "print(f\"Upper bound: ${upper_bound:,.2f}\")\n",
    "\n",
    "# Find all outliers (values outside the bounds)\n",
    "outliers = df_clean[(df_clean['sales'] < lower_bound) | (df_clean['sales'] > upper_bound)]\n",
    "print(f\"\\nNumber of outliers detected: {len(outliers)}\")\n",
    "\n",
    "# Display the outlier records\n",
    "if len(outliers) > 0:\n",
    "    print(\"\\nOutlier records:\")\n",
    "    print(outliers[['date', 'product', 'sales', 'quantity']].sort_values('sales', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09def838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Remove Outliers\n",
    "# ========================================\n",
    "# We'll remove values that fall outside our calculated bounds\n",
    "# This helps prevent extreme values from skewing our analysis\n",
    "\n",
    "# Filter to keep only rows within the bounds\n",
    "# The & operator means \"and\" - both conditions must be true\n",
    "df_clean_no_outliers = df_clean[(df_clean['sales'] >= lower_bound) & (df_clean['sales'] <= upper_bound)]\n",
    "\n",
    "print(f\"Records before removing outliers: {len(df_clean)}\")\n",
    "print(f\"Records after removing outliers: {len(df_clean_no_outliers)}\")\n",
    "print(f\"Outliers removed: {len(df_clean) - len(df_clean_no_outliers)}\")\n",
    "\n",
    "# Use the cleaned dataset for the rest of our analysis\n",
    "df_clean = df_clean_no_outliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55826d1b",
   "metadata": {},
   "source": [
    "### Step 2.5: Add Derived Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Add Derived Columns\n",
    "# ========================================\n",
    "# Create new columns calculated from existing data\n",
    "# These give us additional insights for analysis\n",
    "\n",
    "# Calculate average price per unit for each transaction\n",
    "df_clean['price_per_unit'] = df_clean['sales'] / df_clean['quantity']\n",
    "\n",
    "# Extract time-based features from the date column\n",
    "# First, ensure dates are in datetime format\n",
    "df_clean['month'] = pd.to_datetime(df_clean['date']).dt.month          # Month as number (1-12)\n",
    "df_clean['month_name'] = pd.to_datetime(df_clean['date']).dt.strftime('%B')  # Month name (January, etc.)\n",
    "df_clean['quarter'] = pd.to_datetime(df_clean['date']).dt.quarter     # Quarter (1, 2, 3, or 4)\n",
    "\n",
    "# Create age groups using pd.cut()\n",
    "# bins: boundaries for each group, labels: names for each group\n",
    "df_clean['age_group'] = pd.cut(df_clean['customer_age'], \n",
    "                               bins=[0, 25, 35, 50, 100],\n",
    "                               labels=['18-25', '26-35', '36-50', '50+'])\n",
    "\n",
    "print(\"New columns added:\")\n",
    "print(df_clean[['sales', 'quantity', 'price_per_unit', 'month_name', 'quarter', 'age_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53119df",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Data Subsetting and Filtering\n",
    "\n",
    "Let's create different subsets of data for focused analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee43eb",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Filter by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc02036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Filter by Product Category\n",
    "# ========================================\n",
    "# Create a subset containing only high-value products\n",
    "\n",
    "# .isin() checks if each value is in the provided list\n",
    "# This returns only rows where product is 'Laptop' or 'Monitor'\n",
    "high_value_products = df_clean[df_clean['product'].isin(['Laptop', 'Monitor'])].copy()\n",
    "\n",
    "print(f\"High-value products subset: {len(high_value_products)} records\")\n",
    "print(f\"\\nProduct distribution:\")\n",
    "print(high_value_products['product'].value_counts())\n",
    "\n",
    "# Display summary statistics grouped by product\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(high_value_products.groupby('product')['sales'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8019c",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Filter by Region and Time Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d231bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Filter by Region and Time Period\n",
    "# ========================================\n",
    "# Create a subset for the first half of the year in specific regions\n",
    "\n",
    "# Combine multiple conditions using & (and)\n",
    "# Parentheses are required when using & operator\n",
    "first_half = df_clean[\n",
    "    (df_clean['quarter'].isin([1, 2])) &      # Q1 or Q2\n",
    "    (df_clean['region'].isin(['North', 'East']))  # North or East region\n",
    "].copy()\n",
    "\n",
    "print(f\"First half (Q1-Q2) North & East subset: {len(first_half)} records\")\n",
    "print(f\"\\nRegion distribution:\")\n",
    "print(first_half['region'].value_counts())\n",
    "print(f\"\\nQuarter distribution:\")\n",
    "print(first_half['quarter'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee7ea6",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Filter by Multiple Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Filter by Multiple Conditions\n",
    "# ========================================\n",
    "# Create a subset of high-performing transactions with young, satisfied customers\n",
    "\n",
    "# Combine three conditions using & (and)\n",
    "premium_segment = df_clean[\n",
    "    (df_clean['satisfaction'] >= 4) &                          # High satisfaction (4 or 5)\n",
    "    (df_clean['sales'] > 2000) &                              # High sales (over $2000)\n",
    "    (df_clean['age_group'].isin(['18-25', '26-35']))         # Young customers\n",
    "].copy()\n",
    "\n",
    "print(f\"Premium segment subset: {len(premium_segment)} records\")\n",
    "print(f\"\\nAverage sales: ${premium_segment['sales'].mean():,.2f}\")\n",
    "print(f\"Average satisfaction: {premium_segment['satisfaction'].mean():.2f}\")\n",
    "print(f\"\\nAge group distribution:\")\n",
    "print(premium_segment['age_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceacd34c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Advanced Visualizations\n",
    "\n",
    "Now let's create professional, publication-quality visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addae92c",
   "metadata": {},
   "source": [
    "### Visualization 1: Multi-Panel Sales Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive sales dashboard\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Sales Performance Dashboard - 2024', fontsize=20, fontweight='bold', y=0.995)\n",
    "\n",
    "# Color palette\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E', '#BC4B51']\n",
    "\n",
    "# 1. Sales by Product (Bar chart)\n",
    "product_sales = df_clean.groupby('product')['sales'].sum().sort_values(ascending=True)\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.barh(product_sales.index, product_sales.values, color=colors)\n",
    "ax1.set_xlabel('Total Sales ($)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Total Sales by Product', fontsize=14, fontweight='bold', pad=10)\n",
    "ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, product_sales.values)):\n",
    "    ax1.text(value, bar.get_y() + bar.get_height()/2, \n",
    "             f'${value:,.0f}', \n",
    "             va='center', ha='left', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Sales by Region (Pie chart with explosion)\n",
    "region_sales = df_clean.groupby('region')['sales'].sum()\n",
    "ax2 = axes[0, 1]\n",
    "explode = [0.05 if i == region_sales.argmax() else 0 for i in range(len(region_sales))]\n",
    "wedges, texts, autotexts = ax2.pie(region_sales.values, \n",
    "                                     labels=region_sales.index,\n",
    "                                     autopct='%1.1f%%',\n",
    "                                     colors=colors[:len(region_sales)],\n",
    "                                     explode=explode,\n",
    "                                     shadow=True,\n",
    "                                     startangle=90)\n",
    "ax2.set_title('Sales Distribution by Region', fontsize=14, fontweight='bold', pad=10)\n",
    "\n",
    "# Style the percentage text\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "# 3. Monthly Sales Trend (Line chart)\n",
    "monthly_sales = df_clean.groupby('month')['sales'].agg(['sum', 'mean'])\n",
    "ax3 = axes[1, 0]\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "ax3_twin = ax3.twinx()\n",
    "line1 = ax3.plot(monthly_sales.index, monthly_sales['sum'], \n",
    "                 marker='o', linewidth=2.5, markersize=8, \n",
    "                 color=colors[0], label='Total Sales')\n",
    "line2 = ax3_twin.plot(monthly_sales.index, monthly_sales['mean'], \n",
    "                      marker='s', linewidth=2.5, markersize=8, \n",
    "                      color=colors[1], label='Average Sales', linestyle='--')\n",
    "\n",
    "ax3.set_xlabel('Month', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Total Sales ($)', fontsize=12, fontweight='bold', color=colors[0])\n",
    "ax3_twin.set_ylabel('Average Sales ($)', fontsize=12, fontweight='bold', color=colors[1])\n",
    "ax3.set_title('Monthly Sales Trends', fontsize=14, fontweight='bold', pad=10)\n",
    "ax3.set_xticks(range(1, 13))\n",
    "ax3.set_xticklabels(month_names, rotation=45)\n",
    "ax3.grid(True, alpha=0.3, linestyle='--')\n",
    "ax3.tick_params(axis='y', labelcolor=colors[0])\n",
    "ax3_twin.tick_params(axis='y', labelcolor=colors[1])\n",
    "\n",
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax3.legend(lines, labels, loc='upper left', framealpha=0.9)\n",
    "\n",
    "# 4. Satisfaction vs Sales (Scatter plot with size variation)\n",
    "satisfaction_sales = df_clean.groupby('satisfaction').agg({\n",
    "    'sales': ['mean', 'count']\n",
    "}).reset_index()\n",
    "satisfaction_sales.columns = ['satisfaction', 'avg_sales', 'count']\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "scatter = ax4.scatter(satisfaction_sales['satisfaction'], \n",
    "                      satisfaction_sales['avg_sales'],\n",
    "                      s=satisfaction_sales['count']*2,  # Size based on count\n",
    "                      c=satisfaction_sales['satisfaction'],\n",
    "                      cmap='RdYlGn',\n",
    "                      alpha=0.6,\n",
    "                      edgecolors='black',\n",
    "                      linewidth=2)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(satisfaction_sales['satisfaction'], satisfaction_sales['avg_sales'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax4.plot(satisfaction_sales['satisfaction'], \n",
    "         p(satisfaction_sales['satisfaction']), \n",
    "         \"r--\", linewidth=2, alpha=0.8, label='Trend')\n",
    "\n",
    "ax4.set_xlabel('Customer Satisfaction Score', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Average Sales ($)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Satisfaction vs Average Sales\\n(Bubble size = # of transactions)', \n",
    "              fontsize=14, fontweight='bold', pad=10)\n",
    "ax4.set_xticks([1, 2, 3, 4, 5])\n",
    "ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "ax4.legend()\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax4)\n",
    "cbar.set_label('Satisfaction Score', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63af39",
   "metadata": {},
   "source": [
    "### Visualization 2: Product Performance Heatmap with Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap showing product performance across regions\n",
    "pivot_data = df_clean.pivot_table(\n",
    "    values='sales',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create heatmap\n",
    "im = ax.imshow(pivot_data.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(np.arange(len(pivot_data.columns)))\n",
    "ax.set_yticks(np.arange(len(pivot_data.index)))\n",
    "ax.set_xticklabels(pivot_data.columns, fontsize=12, fontweight='bold')\n",
    "ax.set_yticklabels(pivot_data.index, fontsize=12, fontweight='bold')\n",
    "\n",
    "# Rotate the tick labels for better readability\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\")\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pivot_data.index)):\n",
    "    for j in range(len(pivot_data.columns)):\n",
    "        value = pivot_data.values[i, j]\n",
    "        text = ax.text(j, i, f'${value:.0f}',\n",
    "                      ha=\"center\", va=\"center\", \n",
    "                      color=\"white\" if value > pivot_data.values.mean() else \"black\",\n",
    "                      fontweight='bold', fontsize=11)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel('Average Sales ($)', rotation=-90, va=\"bottom\", \n",
    "                   fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add title and labels\n",
    "ax.set_title('Product Performance Heatmap by Region\\nAverage Sales ($)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Region', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Product', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add grid\n",
    "ax.set_xticks(np.arange(pivot_data.shape[1]+1)-.5, minor=True)\n",
    "ax.set_yticks(np.arange(pivot_data.shape[0]+1)-.5, minor=True)\n",
    "ax.grid(which=\"minor\", color=\"white\", linestyle='-', linewidth=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHeatmap Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Highest average sales: ${pivot_data.values.max():.2f}\")\n",
    "print(f\"Lowest average sales: ${pivot_data.values.min():.2f}\")\n",
    "\n",
    "# Find best performing product-region combination\n",
    "max_idx = np.unravel_index(pivot_data.values.argmax(), pivot_data.values.shape)\n",
    "best_product = pivot_data.index[max_idx[0]]\n",
    "best_region = pivot_data.columns[max_idx[1]]\n",
    "print(f\"\\nBest performing combination: {best_product} in {best_region} region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf4ba2",
   "metadata": {},
   "source": [
    "### Visualization 3: Advanced Multi-Dimensional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive analysis showing multiple dimensions\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Main title\n",
    "fig.suptitle('Multi-Dimensional Sales Analysis', \n",
    "             fontsize=22, fontweight='bold', y=0.98)\n",
    "\n",
    "# 1. Stacked Bar Chart: Sales by Product and Region\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "pivot_region_product = df_clean.pivot_table(\n",
    "    values='sales',\n",
    "    index='product',\n",
    "    columns='region',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "pivot_region_product.plot(kind='bar', stacked=True, ax=ax1, \n",
    "                          color=colors, width=0.7, edgecolor='white', linewidth=1.5)\n",
    "ax1.set_title('Total Sales by Product Across Regions', \n",
    "              fontsize=16, fontweight='bold', pad=15)\n",
    "ax1.set_xlabel('Product', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Total Sales ($)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(title='Region', title_fontsize=12, fontsize=11, \n",
    "           loc='upper right', framealpha=0.9)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# 2. Box Plot: Sales Distribution by Age Group\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "age_groups = df_clean['age_group'].cat.categories\n",
    "data_by_age = [df_clean[df_clean['age_group'] == ag]['sales'].values \n",
    "               for ag in age_groups]\n",
    "\n",
    "bp = ax2.boxplot(data_by_age, labels=age_groups, patch_artist=True,\n",
    "                 notch=True, showmeans=True,\n",
    "                 boxprops=dict(facecolor=colors[0], alpha=0.7),\n",
    "                 medianprops=dict(color='red', linewidth=2),\n",
    "                 meanprops=dict(marker='D', markerfacecolor='yellow', \n",
    "                               markeredgecolor='black', markersize=8),\n",
    "                 whiskerprops=dict(linewidth=1.5),\n",
    "                 capprops=dict(linewidth=1.5))\n",
    "\n",
    "ax2.set_title('Sales Distribution by Age Group', \n",
    "              fontsize=14, fontweight='bold', pad=10)\n",
    "ax2.set_xlabel('Age Group', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Sales ($)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# 3. Grouped Bar Chart: Quantity by Product and Quarter\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "quarterly_product = df_clean.groupby(['product', 'quarter'])['quantity'].sum().unstack()\n",
    "\n",
    "x = np.arange(len(quarterly_product.index))\n",
    "width = 0.2\n",
    "\n",
    "for i, quarter in enumerate(quarterly_product.columns):\n",
    "    offset = width * (i - len(quarterly_product.columns)/2 + 0.5)\n",
    "    ax3.bar(x + offset, quarterly_product[quarter], width, \n",
    "            label=f'Q{quarter}', color=colors[i], alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax3.set_title('Total Quantity Sold by Quarter', \n",
    "              fontsize=14, fontweight='bold', pad=10)\n",
    "ax3.set_xlabel('Product', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Total Quantity', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(quarterly_product.index, rotation=45, ha='right')\n",
    "ax3.legend(title='Quarter', fontsize=10)\n",
    "ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# 4. Violin Plot: Price Distribution by Satisfaction\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "satisfaction_levels = sorted(df_clean['satisfaction'].unique())\n",
    "data_by_satisfaction = [df_clean[df_clean['satisfaction'] == s]['price_per_unit'].values \n",
    "                        for s in satisfaction_levels]\n",
    "\n",
    "parts = ax4.violinplot(data_by_satisfaction, positions=satisfaction_levels,\n",
    "                       widths=0.7, showmeans=True, showmedians=True)\n",
    "\n",
    "# Customize violin plot colors\n",
    "for i, pc in enumerate(parts['bodies']):\n",
    "    pc.set_facecolor(colors[i % len(colors)])\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax4.set_title('Price Distribution by Satisfaction', \n",
    "              fontsize=14, fontweight='bold', pad=10)\n",
    "ax4.set_xlabel('Satisfaction Score', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Price per Unit ($)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(satisfaction_levels)\n",
    "ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Multi-dimensional analysis visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d2406",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Summary Statistics for Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"=\"*70)\n",
    "print(\"DATA CLEANING SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. DATASET OVERVIEW\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Total records in cleaned dataset: {len(df_clean):,}\")\n",
    "print(f\"Total records in original dataset: {len(df):,}\")\n",
    "print(f\"Records removed: {len(df) - len(df_clean):,}\")\n",
    "print(f\"Percentage retained: {(len(df_clean)/len(df)*100):.2f}%\")\n",
    "\n",
    "print(\"\\n2. SALES STATISTICS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Total Sales: ${df_clean['sales'].sum():,.2f}\")\n",
    "print(f\"Average Sale: ${df_clean['sales'].mean():,.2f}\")\n",
    "print(f\"Median Sale: ${df_clean['sales'].median():,.2f}\")\n",
    "print(f\"Standard Deviation: ${df_clean['sales'].std():,.2f}\")\n",
    "\n",
    "print(\"\\n3. PRODUCT PERFORMANCE\")\n",
    "print(\"-\" * 70)\n",
    "product_summary = df_clean.groupby('product').agg({\n",
    "    'sales': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "product_summary.columns = ['Total Sales', 'Avg Sales', 'Transactions']\n",
    "product_summary['Market Share %'] = (product_summary['Total Sales'] / \n",
    "                                     product_summary['Total Sales'].sum() * 100).round(2)\n",
    "print(product_summary.sort_values('Total Sales', ascending=False))\n",
    "\n",
    "print(\"\\n4. REGIONAL PERFORMANCE\")\n",
    "print(\"-\" * 70)\n",
    "region_summary = df_clean.groupby('region').agg({\n",
    "    'sales': ['sum', 'mean'],\n",
    "    'satisfaction': 'mean'\n",
    "}).round(2)\n",
    "region_summary.columns = ['Total Sales', 'Avg Sales', 'Avg Satisfaction']\n",
    "print(region_summary.sort_values('Total Sales', ascending=False))\n",
    "\n",
    "print(\"\\n5. CUSTOMER INSIGHTS\")\n",
    "print(\"-\" * 70)\n",
    "age_summary = df_clean.groupby('age_group').agg({\n",
    "    'sales': ['mean', 'count'],\n",
    "    'satisfaction': 'mean'\n",
    "}).round(2)\n",
    "age_summary.columns = ['Avg Sales', 'Customers', 'Avg Satisfaction']\n",
    "print(age_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"END OF REPORT\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cabe4",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises for Students\n",
    "\n",
    "### Exercise A: Custom Filtering\n",
    "Create a subset of data for:\n",
    "1. Sales in the West region during Q3 and Q4\n",
    "2. Customers aged 36-50 who purchased Tablets or Phones\n",
    "3. Low satisfaction (1-2) transactions with sales > $1000\n",
    "\n",
    "### Exercise B: Additional Visualizations\n",
    "Create the following visualizations:\n",
    "1. A histogram showing the distribution of sales amounts\n",
    "2. A scatter plot showing customer age vs sales with region colors\n",
    "3. A bar chart comparing average satisfaction across products\n",
    "\n",
    "### Exercise C: Data Quality Checks\n",
    "1. Check for any negative values in sales or quantity\n",
    "2. Identify any dates outside the year 2024\n",
    "3. Find products with unusually low or high average prices\n",
    "\n",
    "### Exercise D: Advanced Analysis\n",
    "1. Calculate the correlation between customer age and satisfaction\n",
    "2. Identify the most profitable product-region combination\n",
    "3. Determine if there's a seasonal trend in sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for student exercises\n",
    "# Complete the challenges below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd9f53",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you learned:\n",
    "- âœ… How to identify and handle data quality issues (missing values, duplicates, outliers)\n",
    "- âœ… Techniques for standardizing and transforming data\n",
    "- âœ… Methods to filter and subset data based on multiple criteria\n",
    "- âœ… Creating professional, multi-dimensional visualizations\n",
    "- âœ… Using pandas and matplotlib together for comprehensive analysis\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Always inspect your data first** - understand what you're working with\n",
    "2. **Clean systematically** - handle issues in a logical order\n",
    "3. **Document your decisions** - keep track of what cleaning steps you performed\n",
    "4. **Visualize strategically** - choose the right chart type for your message\n",
    "5. **Tell a story** - combine multiple visualizations to provide complete insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa804375",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Learning Challenges\n",
    "\n",
    "Test your skills with these hands-on challenges! Each challenge includes hints to help you succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634052b",
   "metadata": {},
   "source": [
    "### ðŸŒŸ Challenge 1: Find the Best-Selling Product in Each Region\n",
    "\n",
    "**Task:** Write code to identify which product has the highest total sales in each region.\n",
    "\n",
    "**What you'll practice:**\n",
    "- Grouping data by multiple columns\n",
    "- Finding maximum values\n",
    "- Working with pivot tables or groupby operations\n",
    "\n",
    "**Hints:**\n",
    "- Use `df_clean.groupby()` with both 'region' and 'product' columns\n",
    "- The `.sum()` function will help you get total sales\n",
    "- Try using `.idxmax()` to find the product with maximum sales in each group\n",
    "- Alternatively, you could use `.sort_values()` and `.head(1)` for each group\n",
    "\n",
    "**Expected output:** A result showing each region and its top-selling product with the sales amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f35780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Your code here\n",
    "# TODO: Find the best-selling product in each region\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710a65c",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸŒŸ Challenge 2: Create a Sales Performance Rating System\n",
    "\n",
    "**Task:** Add a new column to `df_clean` called `performance_rating` that categorizes each sale based on the sales amount:\n",
    "- 'Low' for sales < $1,500\n",
    "- 'Medium' for sales between $1,500 and $3,000\n",
    "- 'High' for sales > $3,000\n",
    "\n",
    "Then, count how many transactions fall into each category.\n",
    "\n",
    "**What you'll practice:**\n",
    "- Creating conditional columns\n",
    "- Using `pd.cut()` or `np.where()` or `.apply()`\n",
    "- Value counting and categorization\n",
    "\n",
    "**Hints:**\n",
    "- `pd.cut()` is perfect for creating bins/categories based on ranges\n",
    "- Set the `bins` parameter to [0, 1500, 3000, infinity]\n",
    "- Set the `labels` parameter to ['Low', 'Medium', 'High']\n",
    "- Use `np.inf` for infinity\n",
    "- After creating the column, use `.value_counts()` to see the distribution\n",
    "\n",
    "**Bonus:** Calculate the average satisfaction score for each performance rating level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2: Your code here\n",
    "# TODO: Create performance_rating column and analyze it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4883d",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸŒŸ Challenge 3: Visualize the Age Distribution with Style\n",
    "\n",
    "**Task:** Create a histogram showing the distribution of customer ages with the following features:\n",
    "- Use 10 bins\n",
    "- Add a title and axis labels\n",
    "- Use a custom color\n",
    "- Add a grid for easier reading\n",
    "- Display the mean age as a vertical line in a different color\n",
    "\n",
    "**What you'll practice:**\n",
    "- Creating histograms with matplotlib\n",
    "- Customizing plot appearance\n",
    "- Adding reference lines\n",
    "- Using colors and styling\n",
    "\n",
    "**Hints:**\n",
    "- Use `plt.figure(figsize=(10, 6))` to create a larger figure\n",
    "- `plt.hist()` creates the histogram; use the `bins` and `color` parameters\n",
    "- `plt.axvline()` adds a vertical line; use `df_clean['customer_age'].mean()` for the x position\n",
    "- Use `linestyle='--'` and `linewidth=2` for a dashed line\n",
    "- Don't forget `plt.xlabel()`, `plt.ylabel()`, and `plt.title()`\n",
    "- `plt.grid(alpha=0.3)` adds a subtle grid\n",
    "- Add a legend with `plt.legend()` to label the mean line\n",
    "\n",
    "**Example color:** Try '#3498db' for blue or '#e74c3c' for red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3: Your code here\n",
    "# TODO: Create a styled histogram of customer ages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e20ab",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸŒŸ Challenge 4: Filter and Analyze Peak Season\n",
    "\n",
    "**Task:** Identify the \"peak season\" (the quarter with the highest total sales), then:\n",
    "1. Create a subset of data containing only that quarter\n",
    "2. Calculate which product was most popular (highest quantity sold) during peak season\n",
    "3. Calculate the average customer age during peak season\n",
    "4. Create a simple bar chart showing sales by region during that quarter\n",
    "\n",
    "**What you'll practice:**\n",
    "- Complex filtering with multiple steps\n",
    "- Aggregating data in different ways\n",
    "- Creating focused visualizations\n",
    "- Combining multiple pandas operations\n",
    "\n",
    "**Hints:**\n",
    "- First, use `df_clean.groupby('quarter')['sales'].sum()` to find total sales per quarter\n",
    "- Use `.idxmax()` to find which quarter has the maximum sales\n",
    "- Filter the dataframe: `peak_data = df_clean[df_clean['quarter'] == peak_quarter]`\n",
    "- For most popular product, group by product and sum quantity\n",
    "- Use `.plot(kind='bar')` on grouped data for a quick bar chart\n",
    "- Add `.sort_values(ascending=False)` to see results in descending order\n",
    "\n",
    "**Bonus:** Add the average sales value as a horizontal line on your bar chart!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f11e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4: Your code here\n",
    "# TODO: Analyze peak season data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca84ae4",
   "metadata": {},
   "source": [
    "---\n",
    "### ðŸŒŸ Challenge 5: Create a Customer Satisfaction Dashboard\n",
    "\n",
    "**Task:** Create a 2x2 subplot figure that shows:\n",
    "1. **Top-left:** Pie chart of satisfaction score distribution (how many 1s, 2s, 3s, etc.)\n",
    "2. **Top-right:** Bar chart showing average sales by satisfaction level\n",
    "3. **Bottom-left:** Count of transactions by age group\n",
    "4. **Bottom-right:** Scatter plot of quantity vs. sales (colored by satisfaction)\n",
    "\n",
    "**What you'll practice:**\n",
    "- Creating subplot figures\n",
    "- Multiple plot types in one visualization\n",
    "- Using color to represent additional dimensions\n",
    "- Creating comprehensive dashboards\n",
    "\n",
    "**Hints:**\n",
    "- Start with `fig, axes = plt.subplots(2, 2, figsize=(14, 10))`\n",
    "- Access each subplot using `axes[0, 0]`, `axes[0, 1]`, etc.\n",
    "- For pie chart: `df_clean['satisfaction'].value_counts().plot(kind='pie', ax=axes[0,0])`\n",
    "- For bar chart: use `.groupby('satisfaction')['sales'].mean()` then `.plot(kind='bar')`\n",
    "- For scatter with color: `axes[1,1].scatter(x, y, c=df_clean['satisfaction'], cmap='viridis')`\n",
    "- Add titles to each subplot using `axes[row, col].set_title('Title')`\n",
    "- Use `plt.tight_layout()` at the end to prevent overlap\n",
    "\n",
    "**Extra challenge:** Add a colorbar to the scatter plot to show what the colors mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aefb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 5: Your code here\n",
    "# TODO: Create a 2x2 dashboard with multiple visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853e87e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ’¡ Tips for Success\n",
    "\n",
    "**When working on these challenges:**\n",
    "\n",
    "1. **Read the task carefully** - Make sure you understand what's being asked before you start coding\n",
    "\n",
    "2. **Use the hints** - They're there to guide you in the right direction, not give away the answer\n",
    "\n",
    "3. **Test incrementally** - Don't write all the code at once. Write a little, test it, then add more\n",
    "\n",
    "4. **Check your output** - Does the result make sense? Are there any unexpected values?\n",
    "\n",
    "5. **Review earlier examples** - Look back at the visualizations and code from earlier in the notebook\n",
    "\n",
    "6. **Don't be afraid to experiment** - Try different approaches! Data analysis is creative\n",
    "\n",
    "7. **Use print statements** - `print()` is your friend for debugging and understanding what your code does\n",
    "\n",
    "8. **Google is your ally** - Looking up pandas or matplotlib documentation is a normal part of coding\n",
    "\n",
    "**Remember:** The goal is to learn, not to be perfect. Every mistake is a learning opportunity! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e0b150",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# ðŸ“š Solutions to Learning Challenges\n",
    "\n",
    "Below are the solutions to each challenge. Try to solve them on your own first before looking at these answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba8020",
   "metadata": {},
   "source": [
    "## Solution 1: Find the Best-Selling Product in Each Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf27c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Solution 1: Find Best-Selling Product in Each Region\n",
    "# ========================================\n",
    "\n",
    "# Step 1: Group by both region AND product, then sum sales\n",
    "# This creates a total for each region-product combination\n",
    "region_product_sales = df_clean.groupby(['region', 'product'])['sales'].sum().reset_index()\n",
    "\n",
    "# Step 2: For each region, find the row with the maximum sales\n",
    "# .groupby('region')['sales'].idxmax() returns the index of the max value in each group\n",
    "# .loc[] then selects those specific rows\n",
    "best_sellers = region_product_sales.loc[\n",
    "    region_product_sales.groupby('region')['sales'].idxmax()\n",
    "]\n",
    "\n",
    "# Display results in a formatted table\n",
    "print(\"Best-Selling Product in Each Region:\")\n",
    "print(\"=\" * 60)\n",
    "for _, row in best_sellers.iterrows():\n",
    "    print(f\"{row['region']:10} | {row['product']:10} | ${row['sales']:,.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nAlternative display:\")\n",
    "print(best_sellers.sort_values('sales', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05eec8",
   "metadata": {},
   "source": [
    "---\n",
    "## Solution 2: Create a Sales Performance Rating System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Solution 2: Create Performance Rating Column\n",
    "# ========================================\n",
    "\n",
    "# Create a copy to avoid modifying the original cleaned data\n",
    "df_solution = df_clean.copy()\n",
    "\n",
    "# Use pd.cut() to create categorical bins based on sales values\n",
    "# bins: boundaries for categories [0 to 1500], [1500 to 3000], [3000 to infinity]\n",
    "# labels: names for each category\n",
    "# np.inf represents infinity (no upper limit for 'High')\n",
    "df_solution['performance_rating'] = pd.cut(\n",
    "    df_solution['sales'],\n",
    "    bins=[0, 1500, 3000, np.inf],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Display distribution of performance ratings\n",
    "print(\"Performance Rating Distribution:\")\n",
    "print(\"=\" * 60)\n",
    "print(df_solution['performance_rating'].value_counts().sort_index())\n",
    "\n",
    "# Show statistics for each rating category\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Sales Statistics by Performance Rating:\")\n",
    "print(df_solution.groupby('performance_rating')['sales'].agg(['count', 'mean', 'min', 'max']))\n",
    "\n",
    "# BONUS: Calculate average satisfaction for each performance level\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BONUS: Average Satisfaction by Performance Rating:\")\n",
    "satisfaction_by_performance = df_solution.groupby('performance_rating')['satisfaction'].mean()\n",
    "print(satisfaction_by_performance)\n",
    "\n",
    "# ========================================\n",
    "# Visualize the Results\n",
    "# ========================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Chart 1: Count of transactions by rating\n",
    "df_solution['performance_rating'].value_counts().sort_index().plot(\n",
    "    kind='bar', ax=ax1, color=['#e74c3c', '#f39c12', '#27ae60'], edgecolor='black'\n",
    ")\n",
    "ax1.set_title('Transaction Count by Performance Rating', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Performance Rating', fontweight='bold')\n",
    "ax1.set_ylabel('Number of Transactions', fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Chart 2: Average satisfaction by rating\n",
    "satisfaction_by_performance.plot(kind='bar', ax=ax2, color=['#e74c3c', '#f39c12', '#27ae60'], \n",
    "                                  edgecolor='black')\n",
    "ax2.set_title('Average Satisfaction by Performance Rating', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Performance Rating', fontweight='bold')\n",
    "ax2.set_ylabel('Average Satisfaction Score', fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim(0, 5)  # Set y-axis limits from 0 to 5\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9ebf2",
   "metadata": {},
   "source": [
    "---\n",
    "## Solution 3: Visualize the Age Distribution with Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1eb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Solution 3: Create Styled Histogram of Customer Ages\n",
    "# ========================================\n",
    "\n",
    "# Create a larger figure for better visibility\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Calculate the mean age (we'll show this as a line on the chart)\n",
    "mean_age = df_clean['customer_age'].mean()\n",
    "\n",
    "# Create the histogram\n",
    "# bins=10: divide the age range into 10 equal groups\n",
    "# color: hex color code for blue\n",
    "# edgecolor: color of the bar borders\n",
    "# alpha: transparency (0=invisible, 1=solid)\n",
    "plt.hist(df_clean['customer_age'], \n",
    "         bins=10, \n",
    "         color='#3498db', \n",
    "         edgecolor='black', \n",
    "         alpha=0.7,\n",
    "         linewidth=1.5)\n",
    "\n",
    "# Add a vertical line at the mean age\n",
    "# axvline: adds a vertical line\n",
    "# linestyle='--': dashed line\n",
    "# label: text for the legend\n",
    "plt.axvline(mean_age, \n",
    "            color='#e74c3c', \n",
    "            linestyle='--', \n",
    "            linewidth=3, \n",
    "            label=f'Mean Age: {mean_age:.1f}')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Customer Ages', \n",
    "          fontsize=18, \n",
    "          fontweight='bold', \n",
    "          pad=20)  # pad: space between title and chart\n",
    "plt.xlabel('Customer Age (years)', \n",
    "           fontsize=14, \n",
    "           fontweight='bold')\n",
    "plt.ylabel('Number of Customers', \n",
    "           fontsize=14, \n",
    "           fontweight='bold')\n",
    "\n",
    "# Add a subtle grid for easier reading\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add a legend to explain the mean line\n",
    "plt.legend(fontsize=12, loc='upper right', framealpha=0.9)\n",
    "\n",
    "# Add a text box with statistics\n",
    "median_age = df_clean['customer_age'].median()\n",
    "# transform=plt.gca().transAxes uses relative positioning (0,0)=bottom-left, (1,1)=top-right\n",
    "plt.text(0.02, 0.98, \n",
    "         f'Statistics:\\nMean: {mean_age:.1f}\\nMedian: {median_age:.1f}\\nMin: {df_clean[\"customer_age\"].min()}\\nMax: {df_clean[\"customer_age\"].max()}',\n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=11,\n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing to prevent label cutoff\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Age Distribution Summary:\")\n",
    "print(f\"Mean Age: {mean_age:.2f} years\")\n",
    "print(f\"Median Age: {median_age:.2f} years\")\n",
    "print(f\"Age Range: {df_clean['customer_age'].min()} - {df_clean['customer_age'].max()} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb7bd4",
   "metadata": {},
   "source": [
    "---\n",
    "## Solution 4: Filter and Analyze Peak Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Solution 4: Analyze Peak Season\n",
    "# ========================================\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Find the Peak Quarter\n",
    "# ----------------------------------------\n",
    "# Group by quarter and sum all sales\n",
    "quarterly_sales = df_clean.groupby('quarter')['sales'].sum()\n",
    "\n",
    "# Find which quarter has the maximum sales\n",
    "peak_quarter = quarterly_sales.idxmax()  # Returns the quarter number (1, 2, 3, or 4)\n",
    "peak_sales = quarterly_sales.max()       # Returns the sales value\n",
    "\n",
    "print(\"Quarterly Sales Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(quarterly_sales.sort_index())\n",
    "print(f\"\\nPeak Season: Q{peak_quarter} with total sales of ${peak_sales:,.2f}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Create Subset for Peak Quarter\n",
    "# ----------------------------------------\n",
    "# Filter to include only rows from the peak quarter\n",
    "peak_data = df_clean[df_clean['quarter'] == peak_quarter].copy()\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"Peak Season (Q{peak_quarter}) Analysis:\")\n",
    "print(f\"Total transactions: {len(peak_data)}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Find Most Popular Product (by quantity sold)\n",
    "# ----------------------------------------\n",
    "# Group by product and sum the quantities\n",
    "product_quantity = peak_data.groupby('product')['quantity'].sum().sort_values(ascending=False)\n",
    "most_popular = product_quantity.index[0]    # First item (highest quantity)\n",
    "most_popular_qty = product_quantity.values[0]\n",
    "\n",
    "print(f\"\\nMost Popular Product: {most_popular}\")\n",
    "print(f\"Total Quantity Sold: {most_popular_qty}\")\n",
    "\n",
    "print(\"\\nAll Products by Quantity Sold:\")\n",
    "print(product_quantity)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Calculate Average Customer Age\n",
    "# ----------------------------------------\n",
    "avg_age = peak_data['customer_age'].mean()\n",
    "print(f\"\\nAverage Customer Age in Q{peak_quarter}: {avg_age:.1f} years\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 5: Create Bar Chart of Regional Sales\n",
    "# ----------------------------------------\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"Creating visualization...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Calculate sales by region for the peak quarter\n",
    "regional_sales = peak_data.groupby('region')['sales'].sum().sort_values(ascending=False)\n",
    "colors_region = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']\n",
    "\n",
    "# Create bar chart\n",
    "bars = ax.bar(regional_sales.index, \n",
    "               regional_sales.values, \n",
    "               color=colors_region[:len(regional_sales)],\n",
    "               edgecolor='black',\n",
    "               linewidth=2,\n",
    "               alpha=0.8)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    # Place text at the center of the bar, just above it\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'${height:,.0f}',\n",
    "            ha='center', va='bottom', \n",
    "            fontweight='bold', fontsize=11)\n",
    "\n",
    "# ----------------------------------------\n",
    "# BONUS: Add Average Sales Line\n",
    "# ----------------------------------------\n",
    "avg_sales = regional_sales.mean()\n",
    "# axhline: adds a horizontal line\n",
    "ax.axhline(avg_sales, color='red', linestyle='--', linewidth=2.5, \n",
    "           label=f'Average: ${avg_sales:,.0f}')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title(f'Sales by Region - Q{peak_quarter} (Peak Season)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Region', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Total Sales ($)', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.legend(fontsize=11, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final summary\n",
    "print(f\"\\nRegional Performance in Q{peak_quarter}:\")\n",
    "print(regional_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544b74a",
   "metadata": {},
   "source": [
    "---\n",
    "## Solution 5: Create a Customer Satisfaction Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202a321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 5: Create a 2x2 Customer Satisfaction Dashboard\n",
    "\n",
    "# Create the figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Customer Satisfaction Dashboard', fontsize=20, fontweight='bold', y=0.995)\n",
    "\n",
    "# Define color scheme\n",
    "colors_dashboard = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "\n",
    "# ============================================================\n",
    "# 1. TOP-LEFT: Pie chart of satisfaction score distribution\n",
    "# ============================================================\n",
    "ax1 = axes[0, 0]\n",
    "satisfaction_counts = df_clean['satisfaction'].value_counts().sort_index()\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(\n",
    "    satisfaction_counts.values,\n",
    "    labels=[f'Score {i}' for i in satisfaction_counts.index],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors_dashboard,\n",
    "    startangle=90,\n",
    "    explode=[0.05 if i == satisfaction_counts.idxmax() else 0 for i in satisfaction_counts.index]\n",
    ")\n",
    "\n",
    "# Style the text\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "ax1.set_title('Satisfaction Score Distribution', fontsize=14, fontweight='bold', pad=10)\n",
    "\n",
    "# ============================================================\n",
    "# 2. TOP-RIGHT: Bar chart of average sales by satisfaction\n",
    "# ============================================================\n",
    "ax2 = axes[0, 1]\n",
    "avg_sales_by_satisfaction = df_clean.groupby('satisfaction')['sales'].mean().sort_index()\n",
    "\n",
    "bars = ax2.bar(avg_sales_by_satisfaction.index,\n",
    "               avg_sales_by_satisfaction.values,\n",
    "               color=colors_dashboard,\n",
    "               edgecolor='black',\n",
    "               linewidth=1.5,\n",
    "               alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, val) in enumerate(avg_sales_by_satisfaction.items()):\n",
    "    ax2.text(idx, val, f'${val:.0f}',\n",
    "             ha='center', va='bottom',\n",
    "             fontweight='bold', fontsize=10)\n",
    "\n",
    "ax2.set_title('Average Sales by Satisfaction Level', fontsize=14, fontweight='bold', pad=10)\n",
    "ax2.set_xlabel('Satisfaction Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Average Sales ($)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(avg_sales_by_satisfaction.index)\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================\n",
    "# 3. BOTTOM-LEFT: Count of transactions by age group\n",
    "# ============================================================\n",
    "ax3 = axes[1, 0]\n",
    "age_group_counts = df_clean['age_group'].value_counts().sort_index()\n",
    "\n",
    "bars3 = ax3.barh(range(len(age_group_counts)),\n",
    "                 age_group_counts.values,\n",
    "                 color=colors_dashboard[:len(age_group_counts)],\n",
    "                 edgecolor='black',\n",
    "                 linewidth=1.5,\n",
    "                 alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, val) in enumerate(age_group_counts.items()):\n",
    "    ax3.text(val, i, f' {val}',\n",
    "             ha='left', va='center',\n",
    "             fontweight='bold', fontsize=10)\n",
    "\n",
    "ax3.set_yticks(range(len(age_group_counts)))\n",
    "ax3.set_yticklabels(age_group_counts.index)\n",
    "ax3.set_title('Transaction Count by Age Group', fontsize=14, fontweight='bold', pad=10)\n",
    "ax3.set_xlabel('Number of Transactions', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Age Group', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================\n",
    "# 4. BOTTOM-RIGHT: Scatter plot of quantity vs sales (colored by satisfaction)\n",
    "# ============================================================\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "scatter = ax4.scatter(df_clean['quantity'],\n",
    "                     df_clean['sales'],\n",
    "                     c=df_clean['satisfaction'],\n",
    "                     cmap='viridis',\n",
    "                     s=50,\n",
    "                     alpha=0.6,\n",
    "                     edgecolors='black',\n",
    "                     linewidth=0.5)\n",
    "\n",
    "ax4.set_title('Sales vs Quantity (Colored by Satisfaction)',\n",
    "              fontsize=14, fontweight='bold', pad=10)\n",
    "ax4.set_xlabel('Quantity Sold', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Sales Amount ($)', fontsize=12, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# EXTRA CHALLENGE: Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax4)\n",
    "cbar.set_label('Satisfaction Score', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dashboard created successfully!\")\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"- Most common satisfaction score: {satisfaction_counts.idxmax()}\")\n",
    "print(f\"- Highest average sales at satisfaction level: {avg_sales_by_satisfaction.idxmax()}\")\n",
    "print(f\"- Largest age group: {age_group_counts.idxmax()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cfe60",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ“ What You've Learned\n",
    "\n",
    "By completing these challenges, you've mastered:\n",
    "\n",
    "âœ… **Data Aggregation** - Grouping and summarizing data in multiple ways  \n",
    "âœ… **Conditional Logic** - Creating categories based on value ranges  \n",
    "âœ… **Data Filtering** - Extracting subsets based on complex criteria  \n",
    "âœ… **Statistical Analysis** - Computing means, medians, and distributions  \n",
    "âœ… **Data Visualization** - Creating professional charts with matplotlib  \n",
    "âœ… **Dashboard Creation** - Combining multiple visualizations into comprehensive displays  \n",
    "\n",
    "### Next Steps in Your Data Analytics Journey:\n",
    "\n",
    "1. **Practice with Real Data** - Try applying these techniques to actual datasets from Kaggle or government open data portals\n",
    "2. **Learn Advanced Visualizations** - Explore seaborn for statistical visualizations\n",
    "3. **Master Statistical Tests** - Learn hypothesis testing and correlation analysis\n",
    "4. **Build Interactive Dashboards** - Explore tools like Plotly and Dash\n",
    "5. **Share Your Work** - Create a portfolio of data analysis projects\n",
    "\n",
    "**Remember:** The best way to learn data analytics is by doing. Keep practicing, stay curious, and don't be afraid to experiment with different approaches!\n",
    "\n",
    "---\n",
    "### ðŸŒŸ Congratulations on completing this lesson! ðŸŒŸ\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
